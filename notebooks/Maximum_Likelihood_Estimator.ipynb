{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "%matplotlib inline\n",
    "\n",
    "from scipy.special import binom\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual, IntSlider\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Maximum Likelihood-Schätzer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "Wir stellen für eine einfache Stichprobe $(x_1, \\ldots, x_n)$, d.h. i.i.d gezogene $X_i$, die _Likelihood-Funktion_ bzw. _Likelihood_ in Abhängigkeit des unbekannten Parameters $\\vartheta \\in \\Theta$ auf. Bei $\\Theta$ handelt es sich um den kompletten Parameterraum:\n",
    "$$L(\\vartheta) = f(x_1,\\ldots,x_n|\\vartheta)\\enspace,\\enspace \\vartheta \\in \\Theta$$\n",
    "\n",
    "Damit definieren wir den __Maximum-Likelihood-Schätzer__ (__ML-Schätzer__) $\\hat{\\vartheta}_{ML}$ als:\n",
    "$$ \\hat{\\vartheta} = \\underset{\\hat{\\vartheta} \\in \\Theta}{\\operatorname{argmax}}  L(\\vartheta)$$\n",
    "und für die Transformation mit Hilfe des streng monotonen Logarithmus zur __Log-Likelihoodfunktion__: \n",
    "$$ l(\\vartheta) = \\log L(\\vartheta)$$\n",
    "$$  \\hat{\\vartheta} = \\underset{\\hat{\\vartheta} \\in \\Theta}{\\operatorname{argmax}}  l(\\vartheta)$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Beispiel__: \n",
    "\n",
    "Bernoulli-Versuch mit der Wahrscheinlichkeiten $p$ &rarr; $X_i \\sim B(1,p)$. Damit ergibt sich die Likelihoodfunktion:\n",
    "$$ \\begin{eqnarray}\n",
    "L(\\vartheta) & = & f(x_1,\\ldots,x_n|p)\\enspace,\\enspace p \\in [0,1]\\\\\n",
    "             & = & \\prod_{i = 1}^n f(x_i|p) = \\prod_{i = 1}^n p^x_i (1-p)^{1-x_i} \\\\\n",
    "             & = & p^{\\sum_{i=1}^n x_i} (1-p)^{\\sum_{i=1}^n {1-x_i}} \\\\\n",
    "             & = & p^{n\\overline{x}} (1-p)^{n(1-\\overline{x})}\\end{eqnarray}$$\n",
    "             \n",
    "Bestimmen wir den Maximum-Likelihood-Schätzer für die Wahrscheinlichkeit $p$:\n",
    "$$ \\begin{eqnarray}\n",
    "L(\\vartheta) & = & p^{n\\overline{x}} (1-p)^{n(1-\\overline{x})}\\\\\n",
    "l(\\vartheta) & = & n\\overline{x} \\cdot \\ln p + n(1-\\overline{x})\\cdot \\ln(1-p)\\\\\n",
    "\\text{1. Abl.} = 0: \\enspace \\frac{\\mathrm{d}l(\\vartheta)}{\\mathrm{d} p} & = & n\\overline{x} \\frac{1}{p} - n(1-\\overline{x})\\frac {1}{1-p} = 0 \\\\\n",
    "\\hat{p}_{ML} & = & \\overline{x} \\\\\n",
    "\\text{2. Abl.} < 0: \\enspace \\frac{\\mathrm{d}^2 l(\\vartheta)}{\\mathrm{d} p^2} & = & - n\\overline{x} \\frac{1}{p^2} - n(1-\\overline{x})\\frac {1}{(1-p)^2} < 0 \n",
    "\\end{eqnarray}$$\n",
    "Damit ist die relative Häufigkeit zugleich der ML-Schätzer für $p$:\n",
    "$$\\hat{p}_{ML} = \\frac{1}{n}\\sum_{i=1}^n x_i = \\overline{x}$$\n",
    "Wir haben in einer Stichprobe von $n$ Werten $k$ Realisierungen erhalten. Wie sieht die Likelihoodfunktion aus: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def L(p,n,x):\n",
    "    return p**x * (1-p)**(n-x)\n",
    "\n",
    "def argmax_L(n,x):\n",
    "    return float(x)/n\n",
    "\n",
    "def binomial_likelihood(n,k):\n",
    "    fig, ax = plt.subplots(1, 1)\n",
    "    x = np.linspace(0, 1, 100)\n",
    "    ax.set_xlabel(\"p\")\n",
    "    ax.plot(x, L(x, n, k), 'r-', lw=2, alpha=0.9, label=f'L({k} von {n}| p)')\n",
    "    ax.axvline(x = argmax_L(n,k), label=f'Max. Likelihood-Est. {k}/{n}')\n",
    "    ax.legend(loc='best', frameon=False)\n",
    "    ax.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "# Define sliders for n and k:\n",
    "n_slider = IntSlider(min=1, max=50, value=10, continuous_update=False)\n",
    "k_slider = IntSlider(min=0, max=10, value=0, continuous_update=False)\n",
    "\n",
    "def update_k_range(*args):\n",
    "    k_slider.max = n_slider.value\n",
    "n_slider.observe(update_k_range, 'value')\n",
    "\n",
    "# Define widget for the Likelihood function:\n",
    "binomial_likelihood_widget = interactive(binomial_likelihood,\n",
    "                                      n = n_slider,\n",
    "                                      k = k_slider)\n",
    "display(binomial_likelihood_widget)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Beispiel mit Numerischer Optimierung\n",
    "\n",
    "### Schätzung statistischer Kenngrößen\n",
    "\n",
    "Beispiel entnommen aus \" _Methoden der statistischen Inferenz - Likelihood und Bayes_ \", Leonhard Held, Spektrum Akademischer Verlag Heidelberg 2008.\n",
    "\n",
    "Testverfahren dienen der Früherkennund von Krankheiten, entsprechend sollten sich die Tests durch eine hohe:\n",
    "* __Sensitivität__ = P(Test ist positiv | Proband ist krank)\n",
    "* __Spezifität__ = P(Test ist negativ | Proband ist gesund)\n",
    "\n",
    "auszeichnen. Insbesondere ist es wünschenswert eine niedrige\n",
    "\n",
    "* __Falsch-Negativ-Rage__ = P(Test ist negativ | Proband ist krank)\n",
    "\n",
    "zu erreichen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Beispiel - Darmkrebs-Screening\n",
    "\n",
    "Screening-Untersuchung für Darmkrebs im Rahmen einer australischen Studie an 38000 Patienten. An 6 aufeinanderfolgenden Tagen wurde je ein Test durchgeführt. Bei den 3000 Patienten, bei denen mindestens einer dieser Tests positiv war, wurde mit einer Darmspiegelung das Testergebnis überprüft. Es ergab sich die folgende Häufigkeitsverteilung $Z_k$ für die positiven Testergebnisse bei 196 Krebskranken:\n",
    "\n",
    "| Anzahl der k positiven Tests  | 0  | 1  | 2  | 3  | 4 | 5 | 6 |\n",
    "|:-:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|\n",
    "| Häufigkeit $Z_k$  | NA  | 37  | 22  | 25  | 29 | 34 | 49 |\n",
    "\n",
    "__Aufgrund des gewählten Studiendesigns fehlt die Angabe der Kranken, für die keiner der 6 Tests angeschlagen hat!__\n",
    "&rarr; Wir müssen die __Falsch-Negativ-Rate__ schätzen!\n",
    "\n",
    "$p$ ist die Wahrscheinlichkeit eines positiven Testergebnisses für einen Darmkrebskranken und $X_i$ die Anzahl an positiven Testergebnissen für einen Darmkrebskranken $i$. $p$ soll in der Population nicht variieren &rarr; $X_i$ ist binomial verteilt:\n",
    "\n",
    "$$X_i \\sim B(N,p) \\enspace \\text{mit} \\enspace N = 6$$\n",
    "\n",
    "wobei aber $X_0$ nicht beobachtet wurde &rarr; _gestutzte Binomialverteilung_ :\n",
    "\n",
    "$$P(X_i = k | X_i > 0) = \\frac{P(X_i=k)}{P(X_i>0)}, \\enspace k=1,\\ldots,6$$\n",
    "\n",
    "was auf die Log-Likelihoodfunktion führt:\n",
    "\n",
    "$$ l(p) = \\sum_{k=1}^N Z_k (k \\ln(p) + (N-k)\\ln(1-p)) - n \\ln(1-(1-p)^N) $$\n",
    "\n",
    "$Z_k$ ist die Anzahl der Patienten mit $k$ positiven Testergebnissen und $n = \\sum_{k=1}^N Z_k = 196$ die Gesamtzahl der Patienten mit mindestens einem positiven Testergebnis.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z = np.array([37,22,25,29,34,49])\n",
    "\n",
    "def l(p, Z):\n",
    "    n = Z.sum()\n",
    "    N = len(Z)\n",
    "    vec = np.array(range(6)) + 1\n",
    "    return sum(Z * (vec * np.log(p) + (N - vec) * np.log(1 - p))) - n * np.log(1 - (1- p)**N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_l(p = None):\n",
    "    fig, ax = plt.subplots(1, 1)\n",
    "    x = np.linspace(0.01, 0.99, 100)\n",
    "    ax.set_xlabel(\"p\")\n",
    "    ax.plot(x, [l(p,Z) for p in x], 'r-', lw=2, alpha=0.9, label=f'l(p)')\n",
    "    if p is not None:\n",
    "        ax.axvline(x = p, label=f'Max. Likelihood-Est. p')\n",
    "    ax.legend(loc='best', frameon=False)\n",
    "    ax.grid(True)\n",
    "    plt.show()\n",
    "    \n",
    "plot_l()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Numerisches Suchen des Maximum-Likelihood Schätzers, indem wir das Minimum von $-l(p)$ bestimmen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neg_l(p):\n",
    "    print(f'p: {p[0]}')\n",
    "    return - 1*l(p,Z)\n",
    "\n",
    "#result = minimize(neg_l,[0.1,0.9],method=\"L-BFGS-B\", options={'ftol': 1e-6, 'disp': True})\n",
    "result = minimize(neg_l, 0.5, bounds=[(0.01,0.99)], method=\"L-BFGS-B\", options={'ftol': 1e-7, 'disp': True})\n",
    "p = round(result.x[0],4)\n",
    "print(f'ML-Schätzer für p: {p}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_l(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Damit gitl für die Falsch-Negativ-Rate:\n",
    "$$ \\gamma = P(X_i = 0) \\to \\hat{\\gamma} = (1 - \\hat{p}_{ML})^N$$\n",
    "und damit für $Z_0$:\n",
    "$$ \\hat{Z}_0 = n \\cdot \\frac{\\gamma}{1 - \\gamma}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma = (1-p)**len(Z)\n",
    "print(f'Gamma (FNR):{round(gamma,4)}')\n",
    "Z_0 = Z.sum() * gamma / (1 - gamma)\n",
    "print(f'Z_0:{round(Z_0,2)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Berechnung mit dem EM-Algorithmus\n",
    "\n",
    "Der __EM-Algorithmus (Expectation-Maximization-Algorithm)__ kann iterativ ebenfalls numerisch einen Maximum-Likelihood-Schätzer bestimmen.\n",
    "\n",
    "Für unser Beispiel heißt das:\n",
    "\n",
    "Wären alle Daten für $Z_i$ bekannt, also auch für $Z_0$, ließe sich der Schätzer $\\hat{p}$ relativ einfach bestimmen:\n",
    "$$ \\hat{p} = \\frac{\\sum_{k=0}^{6}k\\cdot Z_k}{6\\cdot \\sum_{k=0}^{6} Z_k}$$\n",
    "$Z_0$ ist aber nicht bekannt. Für ein festes $p$ könnte man aber $Z_0$ berechnen, wie eben gerade als:\n",
    "$$ \\hat{Z}_0 = n \\cdot \\frac{\\gamma}{1 - \\gamma}$$\n",
    "mit $n$ und $\\gamma=(1-p)^N$. Mit Hilfe des EM-Algorithmus iteriert man über beide Ausdrücke und bestimmt die beiden Schätzer $\\hat{Z}_0$ und $\\hat{p}$, die man in der nächsten Iteration für $Z_0$ und $p$ einsetzt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def EM(verbose = False):\n",
    "    p = 0.5\n",
    "    Z_0 = 10\n",
    "    Z = np.array([Z_0,37.0,22.0,25.0,29.0,34.0,49.0])\n",
    "    n = Z[1:].sum()\n",
    "    delta = 1\n",
    "    k = np.array(range(7))\n",
    "    if verbose:\n",
    "            counter = 0\n",
    "            print(f'{counter}. p: {p}, Z_0: {Z_0}')\n",
    "    while (delta > 1e-07):\n",
    "        old_Z_0 = Z[0]\n",
    "        p = np.sum(Z * k) / (6 * Z.sum())\n",
    "        gamma = (1 - p)**6\n",
    "        Z_0 = n * gamma / (1 - gamma)\n",
    "        delta = abs(old_Z_0 - Z_0)\n",
    "        Z[0] = Z_0\n",
    "        if verbose:\n",
    "            counter += 1\n",
    "            print(f'{counter}. p: {p}, Z_0: {Z_0}, Gamma: {gamma}')\n",
    "    return (p, Z_0, gamma)\n",
    "\n",
    "em_p, em_Z_0, em_gamma = EM(True)\n",
    "print(f'p: {round(em_p,4)} und Z_0: {round(em_Z_0,2)} und Gamma: {round(em_gamma,4)}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "statistics",
   "language": "python",
   "name": "statistics"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
